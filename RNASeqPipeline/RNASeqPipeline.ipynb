{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j66Ha64FpiR"
   },
   "source": [
    "# Welcome to the Bash notebook for Neuronal Differentation 2021\n",
    "\n",
    "In this notebook, all the major steps involving the RNASeq analysis process (using bash) will be outlined to the best of my ability, so that everyone can follow along with the RNASeq process!\n",
    "\n",
    "Entries will be formatted in the following manner:\n",
    "\n",
    "1. **Input**: If the data is external to our shared directory at **/project/data/neuronaldifferentiation2021**, then it will provided as such (i.e. a hyperlink leading to the data or script used); however, if the data is internal, within the directory, its path with filename will be included.\n",
    "\n",
    "2. **Code**: This part contains the actual bash script/code used to execute any steps in the RNASeq analysis process.\n",
    "\n",
    "3. **Output**: If the output is another file, it will be outlined as such; if the output is as set of files, the directory  (and path) containing them will be presented; if the output is in some other format or transient in nature, it will be pasted directly into the notebook.\n",
    "\n",
    "*Note: It is not advised (trivial) to actually run this code in the notebook, as it is entirely separate to the Imperial College London servers and as such no directories/files will exist, along with a lack of all the required modules*\n",
    "\n",
    "*This notebook uses the following Bash kernel: https://github.com/takluyver/bash_kernel*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HmW9HSaFpiW"
   },
   "source": [
    "## Part 1: Acquiring the relevant RNASeq data and pre-processing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hwqBi7lFpiW"
   },
   "source": [
    "**1.1** Acquiring the data from the SRA Cloud\n",
    "\n",
    "* The raw data human and mouse data which was obtained through Illumina sequencing can be found <a href=\"https://www.ncbi.nlm.nih.gov/Traces/study/?acc=%20%09PRJNA590754&o=acc_s%3Aa&s=SRR10503052,SRR10503053,SRR10503054,SRR10503055,SRR10503056,SRR10503057,SRR10503058,SRR10503059,SRR10503060,SRR10503061,SRR10503062,SRR10503063,SRR10503064,SRR10503065,SRR10503066,SRR10503067,SRR10503068,SRR10503069,SRR10503070,SRR10503071,SRR10503072,SRR10503073,SRR10503074,SRR10503075,SRR10503076,SRR10503077,SRR10503078,SRR10503079,SRR10503080,SRR10503081,SRR10503082,SRR10503083,SRR10503085,SRR10503086,SRR10503087,SRR10503088,SRR10503089,SRR10503090,SRR10503091,SRR10503092,SRR10503093,SRR10503094,SRR10503095,SRR10503096,SRR10503097,SRR10503100,SRR10503101,SRR10503103,SRR10503104,SRR10503105,SRR10503106,SRR10503107,SRR10503108,SRR10503109,SRR10503110,SRR10503111,SRR10503112,SRR10503113,SRR10503114,SRR10503115,SRR10503116,SRR10503117,SRR10503118,SRR10503119,SRR10503120,SRR10503121,SRR10503122,SRR10503123,SRR10503124,SRR10503125,SRR10503126,SRR10503127,SRR10503128,SRR10503129,SRR10503130,SRR10503131,SRR10503132,SRR10503133,SRR10503134,SRR10503135,SRR10503136\" target=\"_blank\">here</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vPT4FavFpiX"
   },
   "source": [
    "**1.2** The following script was designed to `wget` each individual sample listed above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbjtBN44FpiX"
   },
   "outputs": [],
   "source": [
    "wget https://sra-download.ncbi.nlm.nih.gov/traces/sra13/SRR/010256/*\n",
    "\n",
    "wget https://sra-download.ncbi.nlm.nih.gov/traces/sra20/SRR/010256/*\n",
    "\n",
    "wget https://sra-download.ncbi.nlm.nih.gov/traces/sra33/SRR/010256/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k14RTFf8Fpic"
   },
   "source": [
    "**1.3** The resulting output was all 81 raw samples, in order, which can be found at **/project/data/neuronaldifferentiation2021/sra**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUGgtDBuFpif"
   },
   "source": [
    "**2.1** Converting the data into FASTQ format\n",
    "* In order to make the sample data compatible with any future pipelines, it must be converted into FASTQ format\n",
    "* The toolkit used to make this conversion is **sratoolkit/2.10.9.0**, configured using the `vdbconfig` command\n",
    "* The raw data in its original format can be found at **/project/data/neuronaldifferentiation2021/sra** (from **1.3**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvMsd039Fpig"
   },
   "source": [
    "**2.2** Due to the lengthy nature of this conversion process, a script named **convert.sh** was implemented using `nohup` to ensure that the process could run its course without being interrupted. This script is detailed below:\n",
    "\n",
    "*Note that ***/project/home20/nam220/ND2021*** *is the shortcutted directory with the same base path as in* ***1.3***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vN3ow_1hFpig"
   },
   "outputs": [],
   "source": [
    "#!/bin/sh\n",
    "\n",
    "cd /project/data/neuronaldifferentiation2021/sra #position the script in the working directory\n",
    "\n",
    "echo \"Starting at \"`date` > convert.log #this keeps track script start time convert.log\n",
    "\n",
    "module load sratoolkit/2.10.9.0 #loads the necessary module for sample conversion\n",
    "\n",
    "for i in SRR*  #iterate through each SRR sample\n",
    "do \n",
    "echo \"Processing:  \"$i >> convert.log #this keeps track of sample iteration\n",
    "fastq-dump -O /project/data/neuronaldifferentiation2021/fastq $i  #converts files\n",
    "done\n",
    "\n",
    "echo \"finished at \"`date` >> convert.log #this keeps track of script stop time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARYxInN2Fpig"
   },
   "outputs": [],
   "source": [
    "nohup ./convert.sh > messages.out 2>&1 & #runs the scripts; error messages stored in messages.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1D5dxZIFpig"
   },
   "source": [
    "**2.3** This script created two log-type output files : **/project/data/neuronaldifferentiation2021/sra/convert.log** and **/project/data/neuronaldifferentiation2021/sra/messages.out** tracking the time taken for the task and any error messages/progress reports, respectively. According to **convert.log** this task took approximately 3.5 hours.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDZc0Zv2Fpig"
   },
   "source": [
    "The primary output of **convert.sh** are the FASTQ formatted SRR files from **1.3**, which can be found in **/project/data/neuronaldifferentiation2021/fastq**\n",
    "\n",
    "*Note: these files have been distributed into separate species within the **fastq** directory*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zievs-PBFpih"
   },
   "source": [
    "## Part 2.1: Simplified pipeline (known as orange_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQHh25WrFpih"
   },
   "source": [
    "The orange pipeline is run manually using guidance provided in our genomics practical and **Protocol 1** from <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6373869/\" target=\"_blank\">this</a> paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "to9Z6YaEFpih"
   },
   "source": [
    "**1.1** FastQC was first used to perform a quality control check on the raw reads. This required the .fastq files, which are in separate folders for each species at:\n",
    "\n",
    "* **/project/home20/nam220/ND2021/fastq/human_fastq** for human\n",
    "* **/project/home20/nam220/ND2021/fastq/mouse_fastq** for mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9BrsXd8Fpih"
   },
   "source": [
    "**1.2** The following one-line script was used to run this process in the background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81uT0JlhFpii"
   },
   "outputs": [],
   "source": [
    "module load fastqc\n",
    "\n",
    "cd /project/home20/nam220/ND2021/fastq/human_fastq\n",
    "nohup fastqc *.fastq -o /project/home20/nam220/ND2021/orange_pipeline/FastQC/human_qc/ > progress_human.out 2>&1 &\n",
    "\n",
    "cd /project/home20/nam220/ND2021/fastq/mouse_fastq \n",
    "nohup fastqc *.fastq -o /project/home20/nam220/ND2021/orange_pipeline/FastQC/mouse_qc/ > progress_mouse.out 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZdEuMoqFpii"
   },
   "source": [
    "**1.3** The output files are found in **/project/home20/nam220/ND2021/orange_pipeline/FastQC**\n",
    "* The key output files are .html files named after the .fastq files, which provide a wealth of information regarding the QC parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOPSDHteFpii"
   },
   "source": [
    "**2.1** CutAdapt was used for quality trimming of the FastQ files in:\n",
    "* **/project/home20/nam220/ND2021/fastq/human_fastq** for human\n",
    "* **/project/home20/nam220/ND2021/fastq/mouse_fastq** for mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFEtwb5iFpii"
   },
   "source": [
    "**2.2** The following script was used to achieve this, run in the background using `nohup`\n",
    "\n",
    "*Note: The script included here is for the human fastq, the same would apply for the mouse fastq*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKKXplq8Fpii"
   },
   "outputs": [],
   "source": [
    "#!/bin/sh\n",
    "\n",
    "cd /project/data/neuronaldifferentiation2021/fastq/human_fastq\n",
    "\n",
    "echo \"Starting at \"`date` > trim.log \n",
    "\n",
    "module load cutadapt/1.9.1-python3\n",
    "\n",
    "for i in SRR*\n",
    "do \n",
    "echo \"Processing:  \"$i >> trim.log\n",
    "cutadapt -q 30,30 -o tr_$i $i\n",
    "done\n",
    "\n",
    "echo \"finished at \"`date` >> trim.log\n",
    "\n",
    "for n in tr_SRR*\n",
    "do\n",
    "echo \"Moving: \"$n >> movetrim.log\n",
    "mv $n ./trimmed_human/\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuLuKX_tFpii"
   },
   "outputs": [],
   "source": [
    "nohup ./trimmer.sh > cutadapt_human.out 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1R-PfHwfFpii"
   },
   "source": [
    "**2.3** Three log output files are produced:\n",
    "\n",
    "* cutadapt_human.out or cutadapt_mouse.out (depending on species)\n",
    "* trim.log \n",
    "* movetrim.log \n",
    "\n",
    "These files tracked the progress of the script and noted any standard outputs or error messages.\n",
    "\n",
    "The main files produced from this script are tr_SRR* fastq files, which represent the equivalent files but trimmed at a minimum phred score of 30. These are stored in the CutAdapt directory at **/project/home20/nam220/ND2021/orange_pipeline/CutAdapt/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iuk5kUDpFpij"
   },
   "source": [
    "**3.1** The next step is to use STAR in order to index and align the reference genomes to our trimmed .fastq files. This is done in multiple steps: \n",
    "\n",
    "* First, the genome is indexed\n",
    "* Second, the reads are aligned to the genome\n",
    "\n",
    "The files obtained using `wget` are located <a href=\"https://www.gencodegenes.org/\" target=\"_blank\">here</a> , from gencodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5ju72vcFpij"
   },
   "source": [
    "The following `nohup` script was used to grab the links for each species, and `gunzip` was used to decompress the downloaded files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQ0u_klNFpij"
   },
   "outputs": [],
   "source": [
    "nohup wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_36/gencode.v36.annotation.gtf.gz ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_36/GRCh38.primary_assembly.genome.fa.gz > genome_log.out 2>&1 &\n",
    "\n",
    "gunzip gencode.v36.annotation.gtf.gz \n",
    "gunzip GRCh38.primary_assembly.genome.fa.gz\n",
    "\n",
    "nohup wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/GRCm38.primary_assembly.genome.fa.gz > genome_log.out 2>&1 &\n",
    "\n",
    "gunzip gencode.vM25.annotation.gtf.gz\n",
    "gunzip GRCm38.primary_assembly.genome.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCXPhRl-Fpij"
   },
   "source": [
    "*Note: these are stored in our scratch directories, as they are disposable files (they're huge)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNQwQTLrFpij"
   },
   "source": [
    "**3.2.1** Indexing: using the downloaded fasta and gtf files, we can create a genome index for each species, using **STAR** and `nohup` to run it in background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UiVgh_IRFpij"
   },
   "outputs": [],
   "source": [
    "module load star/2.6.0\n",
    "\n",
    "nohup star --runThreadN 2 --runMode genomeGenerate --genomeDir /project/home20/nam220/ND2021/orange_pipeline/STAR/human_genome_annot --genomeFastaFiles /project/home20/nam220/scratch/genomes/human_genomes/GRCh38.primary_assembly.genome.fa --sjdbGTFfile /project/home20/nam220/scratch/genomes/human_genomes/gencode.v36.annotation.gtf > STAR_human_log.out 2>&1 &\n",
    "\n",
    "#this command is the one run for the human genome, a similar process was applied to the mouse genome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymyTK7CHFpij"
   },
   "source": [
    "**3.2.2** Mapping: the gtf files and the genomeDir are included along with our trimmed fastq files. The command is run through the following script using `nohup`:\n",
    "\n",
    "*Note: The script included here is for the human fastq, the same would apply for the mouse fastq*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bggNEqhFpij"
   },
   "outputs": [],
   "source": [
    "#!/bin/sh\n",
    "\n",
    "cd /project/data/neuronaldifferentiation2021/orange_pipeline/CutAdapt/trimmed_human\n",
    "\n",
    "echo \"Starting at \"`date` > STAR_nam220_errors.log\n",
    "\n",
    "module load star/2.6.0\n",
    "\n",
    "for i in tr_SRR*\n",
    "do \n",
    "echo \"Processing:  \"$i >> STAR_nam220_errors.log\n",
    "star --runThreadN 2 --genomeDir /project/data/neuronaldifferentiation2021/orange_pipeline/STAR/human_genome_annot --sjdbGTFfile /project/scratch/nam220/genomes/human_genomes/gencode.v36.annotation.gtf --sjdbOverhang 100 --readFilesIn $i --outSAMtype BAM SortedByCoordinate --outFileNamePrefix /project/data/neuronaldifferentiation2021/orange_pipeline/STAR/human_starmapped/$i\n",
    "done\n",
    "\n",
    "echo \"finished at \"`date` >> STAR_nam220_errors.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoahUIceFpik"
   },
   "outputs": [],
   "source": [
    "nohup ./map.sh > map_nam220_log.out 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tLZxsdIFpik"
   },
   "source": [
    "**3.3** The subsequent output files were produced for each trimmmed tr_SRR*.fastq sample:\n",
    "\n",
    "* tr_SRR10503052.fastqAligned.out.sam\n",
    "* tr_SRR10503052.fastqAligned.sortedByCoord.out.bam\n",
    "* tr_SRR10503052.fastqLog.final.out\n",
    "* tr_SRR10503052.fastqLog.out \n",
    "* tr_SRR10503052.fastqLog.progress.out \n",
    "* tr_SRR10503052.fastqSJ.out.tab \n",
    "* tr_SRR10503052.fastq_STARgenome \n",
    "\n",
    "*Note: the same output files were created for all other samples*\n",
    "\n",
    "These files are located in **/project/data/neuronaldifferentiation2021/orange_pipeline/STAR/human_starmapped** and **/project/data/neuronaldifferentiation2021/orange_pipeline/STAR/mouse_starmapped**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JcT7r-dFpik"
   },
   "source": [
    "**4.1** Using StringTie, we now count the reads mapped to the annotated genes. This involves using the previously created .bam file, only (as seen in **3.3**), as well as the original .gtf annotation file (as seen in **3.1**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkXpKFCsFpik"
   },
   "source": [
    "**4.2.1** The following script was used along with `nohup` to count the reads:\n",
    "\n",
    "*Note this is the script for the human files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZwLGUDHFpik"
   },
   "outputs": [],
   "source": [
    "#!/bin/sh\n",
    "\n",
    "cd /project/data/neuronaldifferentiation2021/orange_pipeline/StringTie/human_count\n",
    "\n",
    "echo \"Starting at \"`date` > StringTie_errors.log\n",
    "\n",
    "module load stringtie/1.3.4c\n",
    "\n",
    "for i in /project/data/neuronaldifferentiation2021/orange_pipeline/STAR/human_starmapped/*.bam\n",
    "do \n",
    "name=$(echo \"$i\" | cut -c81-94)\n",
    "echo \"Processing:  \"$name >> StringTie_errors.log\n",
    "stringtie $i -p 2 -e -G gencode.v36.annotation.gtf -o ballgown/$name/$name.gtf\n",
    "done\n",
    "\n",
    "echo \"finished at \"`date` >> StringTie_errors.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mFdjxyLFpik"
   },
   "outputs": [],
   "source": [
    "nohup ./counter.sh > stringtie_nam220_log.out 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDsrSh62Fpil"
   },
   "source": [
    "**4.2.2** In order for this data to be used in downstream analysis, a premade python script was run in `python 2.7.11` to convert the resulting files into **matrix.csv** files:\n",
    "\n",
    "*Note the python script can be found at* ***/project/data/huntley/rnaseq_safe/StringTie/prepDE.py*** *and on the GitHub repository under* ***ND2021-ICL/pipe-ABC/RNASeqPipeline/StringTie***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2s_1XcixFpil"
   },
   "outputs": [],
   "source": [
    "module load python/2.7.11\n",
    "\n",
    "nohup python prepDE.py > prepDE_nam220_log.out 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--p0aJvTXkyk"
   },
   "source": [
    "**4.2.3** At a later date, RSEM was also used to obtain readcounts, in order to compare the two program outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_kILSIWX4CT"
   },
   "outputs": [],
   "source": [
    "#!/bin/sh\n",
    "\n",
    "cd /project/data/neuronaldifferentiation2021/orange_pipeline/STAR_RSEM\n",
    "\n",
    "echo \"Starting at \"`date` > RSEM_time_human.log\n",
    "\n",
    "module load perl/5.20.3\n",
    "module load rsem/1.3.1\n",
    "\n",
    "for i in /project/data/neuronaldifferentiation2021/orange_pipeline/STAR_RSEM/human_starmapped/*.toTranscriptome.out.bam\n",
    "do \n",
    "name=$(echo \"$i\" | cut -c86-96)\n",
    "echo \"Processing:  \"$name >> RSEM_time_human.log\n",
    "rsem-calculate-expression --bam --no-bam-output -p 8  \\ $i /project/data/neuronaldifferentiation2021/orange_pipeline/STAR_RSEM/human_RSEM_ref/ref /project/data/neuronaldifferentiation2021/orange_pipeline/RSEM/human_counts/$name\n",
    "\n",
    "done\n",
    "\n",
    "echo \"finished at \"`date` >> RSEM_time_human.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cU-RzRVxX6U3"
   },
   "outputs": [],
   "source": [
    "nohup ./RSEM_counter_human.sh > RSEM_nam220_log.out 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyHdZvt_Fpil"
   },
   "source": [
    "**4.3** The resulting output files can be found in **/StringTie/human_count** and **/StringTie/mouse_count**:\n",
    "\n",
    "* .py, .sh and .log/out files for running the above scripts and tracking them\n",
    "* transcript_count_matrix.csv\n",
    "* gene_count_matrix.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky3Uuo0rT8J6"
   },
   "source": [
    "**At this point, these .csv files are used in conjunction with DESeq2 and DP_GP cluster for downstream analysis. Please refer to the RNASeqAnalysis and Clustering notebooks for the next instructions.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RNASeq Analysis Final Version.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
