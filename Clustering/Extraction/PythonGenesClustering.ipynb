{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Python notebook for Neuronal Differentation 2021 Clustering\n",
    "\n",
    "**In this notebook, all the major steps involving the scraping and filtering of orthologous genes related to protein degradation ontologies (using python) will be shown**\n",
    "\n",
    "### 4 scripts can be found in this notebook:\n",
    "\n",
    "**1. ontologyscraper.py**\n",
    "\n",
    "Used to retrieve all genes in select protein degradation ontologies, obtaining a **master.csv** (which can be found at **pipe-ABC/Clustering/GenesOfInterest/master.csv**)\n",
    "\n",
    "**2. mergedvsmaster.py**\n",
    "\n",
    "Used to compare the **master.csv** containing relevant genes with the list of genes obtained through our RNASeqPipeline, which have been merged with a metadata file matching ENSG IDs to Gene IDs (**merged.csv**, which can be found at **pipe-ABC/Clustering/GenesOfInterest/merged.csv**) for gene to gene comparison between files\n",
    "\n",
    "**3. clusteryoink.py**\n",
    "\n",
    "Used to pull out genes which are orthologous between the two species only from **vsd_transformed.csv** (which can be found at **pipe-ABC/Clustering/GenesOfInterest/vsd_transformed.csv**), matching them with the **master.csv** and which will serve as the dataset for clustering.\n",
    "\n",
    "**4. clusterfilter.py**\n",
    "\n",
    "Used to pull out significant recurring clusters (from **filtered_clusters_human.csv** and **filtered_clusters_mouse.csv**, which can both be found at **pipe-ABC/Clustering/GenesOfInterest/**)  between species for further analysis. Note that this step was executed AFTER clustering was performed.\n",
    "\n",
    "*In total, this process found 779 genes of interest, which resulted in a total of 204 genes after all 4 steps were executed.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ontologyscraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('master.csv', 'a') as infile:\n",
    "\n",
    "    df_human = pd.read_csv('human_ontology.tsv',sep='\\t',names=[\"Label\", \"Gene\", \"Taxon\", \"Reference\"])\n",
    "    df_mouse = pd.read_csv('mouse_ontology.tsv',sep='\\t',names=[\"Label\", \"Gene\", \"Taxon\", \"Reference\"])\n",
    "\n",
    "    df_mouse['Label'] = df_mouse['Label'].str.upper()\n",
    "\n",
    "    df_final = pd.merge(df_human, df_mouse, on=['Label'])\n",
    "    \n",
    "    df_master = df_final.drop_duplicates(subset='Label',keep='first',ignore_index=True)\n",
    "    \n",
    "    df_master=df_master.assign(Ontology='OGXXXXXX') #this line requires the user to input the ontology ID they are actively scraping\n",
    "    \n",
    "    df_master.to_csv('master.csv', mode='a', header=False, index=False)\n",
    "    \n",
    "infile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mergedvsmaster.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "#for human\n",
    "\n",
    "with open(\"output.csv\", \"w\", newline=\"\") as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "        \n",
    "    df = pd.read_csv(\"master.csv\")\n",
    "    \n",
    "    genes = df[\"Label\"].tolist()\n",
    "        \n",
    "    with open(\"merged.csv\", \"r\") as merged_file:\n",
    "    \n",
    "        csv_merged = csv.reader(merged_file, delimiter=\",\")\n",
    "            \n",
    "        for row_merged in csv_merged: \n",
    "            merged = row_merged[2]\n",
    "            checker = str(merged)\n",
    "            #print(checker)\n",
    "          \n",
    "               \n",
    "            if merged in genes:\n",
    "                \n",
    "                ontology = df.loc[df['Label'] == checker, 'Ontology'].iloc[0]\n",
    "                  \n",
    "                  \n",
    "                row_merged.append(ontology)\n",
    "                writer.writerow(row_merged)\n",
    "                \n",
    "        merged_file.close()\n",
    "\n",
    "out_file.close()\n",
    "\n",
    "\n",
    "#for mouse\n",
    "\n",
    "with open(\"output.csv\", \"w\", newline=\"\") as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "        \n",
    "    df = pd.read_csv(\"master.csv\")\n",
    "    \n",
    "    genes = df[\"Label\"].tolist()\n",
    "        \n",
    "    with open(\"merged.csv\", \"r\") as merged_file:\n",
    "    \n",
    "        csv_merged = csv.reader(merged_file, delimiter=\",\")\n",
    "            \n",
    "        for row_merged in csv_merged: \n",
    "            merged = row_merged[2]\n",
    "            merged = merged.upper()\n",
    "            checker = str(merged)\n",
    "          \n",
    "            if merged in genes:\n",
    "                \n",
    "                ontology = df.loc[df['Label'] == checker, 'Ontology'].iloc[0]\n",
    "                  \n",
    "                  \n",
    "                row_merged.append(ontology)\n",
    "                writer.writerow(row_merged)\n",
    "                \n",
    "        merged_file.close()\n",
    "\n",
    "out_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clusteryoinker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"cluster_output_combined.csv\", \"w\", newline=\"\") as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "        \n",
    "    df = pd.read_csv(\"master.csv\")\n",
    "    \n",
    "    genes = df[\"Label\"].tolist()\n",
    "        \n",
    "    with open(\"vsd_transformed.csv\", \"r\") as merged_file:\n",
    "    \n",
    "        csv_transformed = csv.reader(merged_file, delimiter=\",\")\n",
    "            \n",
    "        for row_merged in csv_transformed: \n",
    "            merged = row_merged[0]\n",
    "            checker = str(merged)\n",
    "            print(checker)\n",
    "               \n",
    "            if merged in genes:\n",
    "                  \n",
    "                writer.writerow(row_merged)\n",
    "                \n",
    "        merged_file.close()\n",
    "\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clusterfilter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv \n",
    "import numpy as np\n",
    "\n",
    "with open(\"recurring_clusters.csv\", \"w\", newline=\"\") as out_file:\n",
    "    \n",
    "    writer = csv.writer(out_file)\n",
    "        \n",
    "    df = pd.read_csv(\"filtered_clusters_human.csv\")\n",
    "    \n",
    "    genes = df[\"gene\"].tolist()\n",
    "        \n",
    "    with open(\"filtered_clusters_mouse.csv\", \"r\") as in_file:\n",
    "    \n",
    "        csv_transformed = csv.reader(in_file, delimiter=\",\")\n",
    "            \n",
    "        for row_merged in csv_transformed: \n",
    "            merged = row_merged[1]\n",
    "            checker = str(merged)\n",
    "            print(checker)\n",
    "               \n",
    "            if merged in genes:\n",
    "                  \n",
    "                writer.writerow(row_merged)\n",
    "                \n",
    "        in_file.close()\n",
    "        \n",
    "        print('MOUSE DONE, MOVING ONTO HUMAN')\n",
    "    with open(\"filtered_clusters_human.csv\", \"r\") as in_file:\n",
    "        \n",
    "        df1 = pd.read_csv(\"filtered_clusters_mouse.csv\")\n",
    "    \n",
    "        genes1 = df1[\"gene\"].tolist()\n",
    "    \n",
    "        csv_transformed = csv.reader(in_file, delimiter=\",\")\n",
    "            \n",
    "        for row_merged in csv_transformed: \n",
    "            merged = row_merged[1]\n",
    "            checker = str(merged)\n",
    "            print(checker)\n",
    "               \n",
    "            if merged in genes1:\n",
    "                  \n",
    "                writer.writerow(row_merged)\n",
    "                \n",
    "        \n",
    "                \n",
    "        in_file.close()\n",
    "    \n",
    "\n",
    "out_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
